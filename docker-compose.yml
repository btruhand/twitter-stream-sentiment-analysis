version: "2.4"
services:
  streaming-web:
    build:
      context: .
      dockerfile: ./docker/Dockerfile-server
    image: bigdata-project-tornado:latest
    ports:
      - "80:10080"
    depends_on:
      kafka1:
        condition: service_healthy
      kafka2:
        condition: service_healthy
    networks:
      - web_rabbitmq
      - kafka_cluster
    cpus: 1.0
    mem_limit: 100M
    blkio_config:
      weight: 250

  rabbitmq1:
    build:
      context: .
      dockerfile: ./docker/Dockerfile-rabbitmq
    image: bigdata-project-mq:latest
    networks:
      - web_rabbitmq
      - backend_rabbitmq
    ports:
      - "5672:5672"
      - "15672:15672"
    expose:
      - "4369"
      - "5672"
      - "25672"
    hostname: rabbitmq1
    env_file:
      - ./rabbitmq/.env
    volumes:
      - rabbitmq_data_1:/var/lib/rabbitmq
      - ./rabbitmq/rabbitmq.conf:/etc/rabbitmq/rabbitmq.conf
      - ./rabbitmq/definitions.json:/etc/rabbitmq/definitions.json # this makes some things easier, some things harder
      # would not do it in a production setting, but here it is just to ease things up
    healthcheck:
      test: ["CMD", "./tmp/wait-for-it.sh", "localhost:5672", "-t", "10"]
      interval: 25s
      retries: 2
      start_period: 25s
    restart: on-failure
    mem_limit: 150M
    cpus: 1
    blkio_config:
      weight: 300

  rabbitmq2:
    build:
      context: .
      dockerfile: ./docker/Dockerfile-rabbitmq
    image: bigdata-project-mq:latest
    # image: rabbitmq:3.7-management
    networks:
      - web_rabbitmq
      - backend_rabbitmq
    expose:
      - "5672"
    hostname: rabbitmq2
    env_file:
      - ./rabbitmq/.env
    volumes:
      - rabbitmq_data_2:/var/lib/rabbitmq
      - ./rabbitmq/rabbitmq.conf:/etc/rabbitmq/rabbitmq.conf
      - ./rabbitmq/definitions.json:/etc/rabbitmq/definitions.json
    depends_on:
      rabbitmq1:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "./tmp/wait-for-it.sh", "localhost:5672", "-t", "10"]
      interval: 25s
      retries: 2
      start_period: 25s
    restart: on-failure
    mem_limit: 150M
    cpus: 1
    blkio_config:
      weight: 300

  zookeeper:
    image: bitnami/zookeeper:latest
    expose:
      - "2181"
    networks:
      - kafka_cluster
    environment:
      - ZOO_ENABLE_AUTH=yes
      - ZOO_SERVER_USERS=kafka
      - ZOO_SERVER_PASSWORDS=zookafka
    mem_limit: 300M
    volumes:
      - zookeeper_data:/bitnami/zookeeper
  kafka1:
    build:
      context: .
      dockerfile: ./docker/Dockerfile-kafka
    image: bigdata-project-kafka:latest
    expose:
      - "9092"
    env_file: .kafka.env
    environment:
      - KAFKA_BROKER_ID=1
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka1:9092
    depends_on:
      - zookeeper
    networks:
      - kafka_cluster
    volumes:
      - kafka_data_1:/bitnami/kafka
    healthcheck:
      test: ["CMD", "./wait-for-it.sh", "localhost:9092", "-t", "10"]
      interval: 5s
      retries: 3
      start_period: 5s
    restart: on-failure
    cpus: 2.0
    mem_limit: 1024M
    blkio_config:
      weight: 600
  kafka2:
    build:
      context: .
      dockerfile: ./docker/Dockerfile-kafka
    image: bigdata-project-kafka:latest
    expose:
      - "9092"
    env_file: .kafka.env
    environment:
      - KAFKA_BROKER_ID=2
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka2:9092
    depends_on:
      - zookeeper
    networks:
      - kafka_cluster
    healthcheck:
      test: ["CMD", "./wait-for-it.sh", "localhost:9092", "-t", "10"]
      interval: 5s
      retries: 3
      start_period: 5s
    restart: on-failure
    volumes:
      - kafka_data_2:/bitnami/kafka
    mem_limit: 1024M
    cpus: 2.0
    blkio_config:
      weight: 600
    
  streamer:
    build:
      context: .
      dockerfile: ./docker/Dockerfile-streaming
    image: streaming-worker:latest
    networks:
      - backend_rabbitmq
      - kafka_cluster
    expose:
      - "9999"
    depends_on:
      rabbitmq1:
        condition: service_healthy
      rabbitmq2:
        condition: service_healthy
      kafka1:
        condition: service_healthy
      kafka2:
        condition: service_healthy
    cpus: 1.0
    scale: 2
    mem_limit: 100M
    blkio_config:
      weight: 350
  
  # not using spark standalone cluster because it takes too much power
  spark-app:
    build:
      context: .
      dockerfile: ./docker/Dockerfile-spark-app
    image: bigdata-project-spark-sentiment:latest
    environment:
      - SPARK_MASTER_URL=local
      - SPARK_CONCURRENCY=*
      - ENABLE_INIT_DAEMON=false
    depends_on:
      kafka1:
        condition: service_healthy
      kafka2:
        condition: service_healthy
    networks:
      - spark_network
      - kafka_cluster
    restart: on-failure
    mem_limit: 8G
    blkio_config:
      weight: 800
    cpus: 4.0

networks:
  web_rabbitmq:
    driver: bridge
    name: bigdata-project-web-rabbitmq
  backend_rabbitmq:
    driver: bridge
    name: bigdata-project-backend-rabbitmq
  kafka_cluster:
    driver: bridge
    name: bigdata-project-kafka-cluster
  spark_network:
    driver: bridge
    name: bigdata-project-spark-cluster

volumes:
  rabbitmq_data_1:
    name: bigdata-project-rabbitmq-data-1
  rabbitmq_data_2:
    name: bigdata-project-rabbitmq-data-2
  zookeeper_data:
    name: bigdata-project-zookeeper-data
  kafka_data_1:
    name: bigdata-project-kafka-data-1
  kafka_data_2:
    name: bigdata-project-kafka-data-2